<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Coding cheat sheet</title>
    <link>https://matteo-gz.github.io/coding/</link>
    <description>Recent content on Coding cheat sheet</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://matteo-gz.github.io/coding/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>01. 分布式简介</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/define/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/define/</guid>
      <description> 极客时间.分布式技术原理与算法解析 笔记
分布式定义 # 分布式其实就是将相同或相关的程序运行在多台计算机上，从而实现特定目标的一种计算方式.
分布式形态
数据并行 任务并行 分布式驱动力量
性能 可用性 可扩展性 指标 # 性能 # 吞吐量 QPS（Queries Per Second） TPS（Transactions Per Second） BPS（Bits Per Second） 响应时间 完成时间 资源占用 # 空载资源占用 满载资源占用 可用性 # 系统的可用性可以用系统停止服务的时间与总的时间之比衡量
某功能的失败次数与总的请求次数之比来衡量
可扩展性 # 当任务的需求随着具体业务不断提高时，除了升级系统的性能做垂直 / 纵向扩展外， 另一个做法就是通过增加机器的方式去水平 / 横向扩展系统规模。
系统可扩展性的常见指标是加速比（Speedup），也就是一个系统进行扩展后相对扩展前的性能提升
不同场景下分布式系统的指标
电商系统 //重吞吐量 IoT //资源占用指标,可以资源占用KB级的 电信业务 // 响应时间、完成时间，以及可用性 HPC // 任务执行时间极长,水平扩展来提高系统的加速比 大数据 // 扩展性 云计算 // 减少用户操作时间,降低系统资源开销 区块链 // 吞吐量和完成时间 </description>
    </item>
    
    <item>
      <title>02. 协调与同步</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/coordination/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/coordination/</guid>
      <description>极客时间.分布式技术原理与算法解析 笔记
分布式互斥 # 在分布式系统里，排他性的资源访问方式，叫作分布式互斥（Distributed Mutual Exclusion）， 而这种被互斥访问的共享资源就叫作临界资源（Critical Resource）
集中式算法 # 协调者参与
graph TB subgraph 分布式系统 A[程序 A] --&gt; C[协调者] B[程序 B] --&gt; C[协调者] end subgraph 互斥算法 C[协调者] --&gt; D[发送请求] D --&gt; E[检查资源状态] E --&gt; |资源空闲| F[授权访问] E --&gt; |资源占用| G[排号等待] G --&gt; H[接收通知] H --&gt; D F --&gt; I[访问资源] I --&gt; J[释放资源] J --&gt; |通知协调者| C end 优点
开发和实现简单,不存在节点间的协调问题 数据一致性易于控制 故障修复相对简单 缺点
可靠性和性能依赖于中心节点 中心节点出故障或压力过大会导致整体服务挂掉 难以水平扩展以提升吞吐量 分布式算法 # 定义</description>
    </item>
    
    <item>
      <title>02.1 分布式事务</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/dt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/dt/</guid>
      <description>简介 # 分布式事务，就是在分布式系统中运行的事务，由多个本地事务组合而成
方案
基于 XA 协议的二阶段提交协议方法 三阶段提交协议方法 基于消息的最终一致性方法 XA二阶段提交 # 二阶段提交: Two-Phase Commit，2PC
XA(Extended Architecture)是一个分布式事务协议
涉及对象
事务管理器 // 事务协调者Transaction Coordinator,负责各个本地资源的提交和回滚 本地资源管理器 // 分布式事务的参与者Participants,执行实际的操作,如数据库或其他资源 执行过程
投票（voting） 提交（commit） 举例
第一阶段 sequenceDiagram participant 协调者 participant 订单系统 participant 库存系统 协调者-&gt;&gt;订单系统: 询问订单情况 订单系统--&gt;&gt;协调者: 锁定用户A相关订单,增加一条购买100件T恤的订单 订单系统--&gt;&gt;协调者: 回复同意消息&#34;Yes&#34; 协调者-&gt;&gt;库存系统: 询问出货情况 库存系统--&gt;&gt;协调者: 回复库存不足信息&#34;No&#34; 第二阶段 sequenceDiagram participant 协调者 participant 订单系统 participant 库存系统 协调者-&gt;&gt;订单系统: 发送&#34;DoAbort&#34;消息 订单系统--&gt;&gt;协调者: 回复&#34;HaveCommitted&#34;消息 协调者-&gt;&gt;库存系统: 发送&#34;DoAbort&#34;消息 库存系统--&gt;&gt;协调者: 回复&#34;HaveCommitted&#34;消息 缺点 # 同步阻塞问题 单点故障问题 数据不一致问题 三阶段提交方法 # 三阶段提交协议（Three-phase commit protocol，3PC）,三阶段提交引入了超时机制和准备阶段</description>
    </item>
    
    <item>
      <title>03. 资源与负载</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/resource/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/resource/</guid>
      <description> 极客时间.分布式技术原理与算法解析 笔记
分布式体系结构 # 集中式结构 # Google Borg Kubernetes Mesos 非集中式结构 # Akka 集群 Redis 集群 Cassandra 集群 调度 # 而为用户任务寻找合适的服务器这个过程，在分布式领域中叫作调度.
调度是以任务为单位的，而不是以作业为单位.
单体调度 # 是由一个中央调度器去管理整个集群的资源信息和任务调度，也就是说所有任务只能通过中央调度器进行调度
Borg 调度算法
可行性检查，找到一组可以运行任务的机器（Borglet） 评分，从可行的机器中选择一个合适的机器（Borglet） 最差匹配 最佳匹配 两层调度 # 是将资源管理和任务调度分为两层来调度。
第一层调度器负责集群资源管理，并将可用资源发送给第二层调度 第二层调度接收到第一层调度发送的资源，进行任务调度 共享状态调度 # 多个调度器，每个调度器都可以看到集群的全局资源信息，并根据这些信息进行任务调度
分布式计算 # MapReduce // 分而治之 Stream // 实时 Actor Erlang/OTP Akka Quasar (Java) Pipeline 分布式通信 # RPC Pub/Sub 消息队列 </description>
    </item>
    
    <item>
      <title>03.1 分布式存储</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/ds/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/ds/</guid>
      <description>CAP # CA CP AP 场景 单机 强一致性,金融银行 及时响应,容忍一致性,商品查询 应用 Mysql Redis,Hbase,ZooKeeper CoachDB,Cassandra,DynamoDB 数据分片 # 数据分片即按照一定的规则将数据路由到相应的存储节点中，从而降低单存储节点带来的读写压力
哈希分片 根据key的哈希值来决定分配到哪个分片 不依赖key的顺序,只依赖哈希函数 范围分片 根据key的大小顺序来决定属于哪个分片范围 依赖于key有明确的大小顺序 一致性哈希环 将节点和数据项映射到一个虚拟圆环空间上 通过这种映射来实现分片和负载均衡 对节点添加和删除影响较小 一致性哈希环 # hash算法的缺陷 好刚: 7分钟视频详解一致性hash 算法
以图片服务器举例,我们希望图片均匀落在不同的图片服务器上.
以图片名为key,hash后再根据机器数取模,在此规则下.
假设图片hash=6,机器数为3, %3=0,则图片放置在0号服务器.
此时,我们增加1台机器,机器数为4,图片hash依旧为6,%4=2,则映射到了2号服务器,
此时原本在0号服务器的图片,去了2号服务器查找不存在,又要通过后端服务查找一遍,可能导致缓存雪崩.
一致性哈希环 则可以减少数据失效程度. hash偏斜与虚拟节点 数据结构分类 # 分布式数据库
MySQL Sharding Microsoft SQL Azure Google Spanner Alibaba OceanBase KV数据库
Redis Memcache 分布式存储系统
Ceph GFS HDFS Swift 数据一致性 # 强一致性 数据一致性 Raft 协议 Gossip 协议 Gossip # 分布式原理：10分钟带你全面了解Gossip协议！</description>
    </item>
    
    <item>
      <title>b &#43; 树</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/b_tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/b_tree/</guid>
      <description>为什么 MySQL 采用 B+ 树作为索引?
树结构的对比种类 # 二叉查找树 平衡二叉查找树 B tree B + tree 二叉查找树 # 二叉查找树(Binary Search Tree)的特点是一个节点的左子树的所有节点都小于这个节点，右子树的所有节点都大于这个节点
查询和插入删除效率较高,但平衡性不佳,最坏情况下时间复杂度为O(n)
当每次插入的元素都是二叉查找树中最大的元素，二叉查找树就会退化成了一条链表，查找数据的时间复杂度变成了 O(n)
遍历 # 先序遍历按照“根节点-&amp;gt;左子树-&amp;gt;右子树”的顺序进行遍历 中序遍历按照“左子树-&amp;gt;根节点-&amp;gt;右子树”的顺序进行遍历 后序遍历按照“左子树-&amp;gt;右子树-&amp;gt;根结点”的顺序进行遍历 平衡二叉查找树 # AVL树为实现平衡二叉查找树的数据结构
每个节点的左子树和右子树的高度差不能超过 1
时间复杂度降低到O(log n)
不管平衡二叉查找树还是红黑树，都会随着插入的元素增多，而导致树的高度变高，这就意味着磁盘 I/O 操作次数多，会影响整体数据查询的效率
B tree # 当树的节点越多的时候，并且树的分叉数 M 越大的时候，M 叉树的高度会远小于二叉树的高度
B + tree # B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此数据量相同的情况下，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，查询底层节点的磁盘 I/O次数会更少
B+ 树所有叶子节点间还有一个链表进行连接，这种设计对范围查找非常有帮助</description>
    </item>
    
    <item>
      <title>BASE理论</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/distributed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/distributed/</guid>
      <description> CAP原则 # CAP原则（CAP theorem）是一个分布式系统理论，它指出在一个分布式计算系统中，无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三个目标。
一致性（Consistency） # 要求系统中的所有节点在同一时间具有相同的数据副本，即读操作应该总是返回最新的写操作结果。
可用性（Availability） # 要求系统在任何时间都能够提供响应，即系统不会因为部分节点的故障而导致整个系统不可用。
分区容错性（Partition tolerance） # 要求系统能够继续运行，即使系统内的节点因为网络问题而无法互相通信。
根据CAP原则，当一个分布式系统发生网络分区时，为了保证系统的可用性和分区容错性，必须选择放弃一致性。这意味着在网络分区的情况下，系统可以选择提供最新的数据副本（追求一致性），但这可能导致某些节点无法访问；或者系统可以继续提供访问服务（追求可用性），但可能会返回不一致的数据。
需要注意的是，CAP原则并不是指分布式系统必须选择放弃一致性，而是在面临网络分区时需要做出权衡。不同的分布式系统可能会根据具体需求和设计目标，在一致性、可用性和分区容错性之间作出不同的选择。
BASE理论 # BASE理论是对CAP原则的一种实践指导，它是对传统ACID（原子性、一致性、隔离性和持久性）事务模型的一种松散的替代理论。BASE代表着基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）。
基本可用（Basically Available） # 系统保证在面对部分故障或者分区的情况下，仍能够提供基本的可用性和服务能力，即系统能够对用户的请求做出响应，尽管可能会有部分功能受限或者性能下降。
软状态（Soft State） # 系统中的数据状态不需要实时保持一致，允许在一段时间内存在不同节点之间的数据副本不一致的情况。这意味着系统可以容忍一定的数据冗余和延迟，以换取更高的可用性和性能。
最终一致性（Eventually Consistent） # 系统会在一段时间内尽可能地使数据达到一致状态，但并不要求实时保证一致性。系统允许在数据复制和同步过程中存在一定的延迟和不一致，但最终会达到一致的状态。
BASE理论的核心思想是放宽对一致性的要求，以换取更高的可用性、性能和分布式容错性。相比于ACID事务模型的强一致性和事务隔离性，BASE理论提供了更灵活的设计选择，特别适用于大规模分布式系统和互联网应用场景。在BASE理论下，系统设计者需要根据具体的业务需求和系统特点，权衡一致性与可用性之间的取舍，并选择适当的一致性模型和数据同步策略。
幂等 # 任意次执行都会产生相同的结果：无论操作执行多少次，结果都是相同的，不会受到重复执行的影响。 重复执行不会引起不良影响：对于已经执行过的操作，重复执行不会引起任何不良的副作用或状态变化。 </description>
    </item>
    
    <item>
      <title>chan</title>
      <link>https://matteo-gz.github.io/coding/docs/go/chan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/chan/</guid>
      <description>操作chan # 创建chan
make(chan T, [capacity]) // 无缓冲,创建一个int类型的channel ch := make(chan int) // 有缓冲,创建一个容量为5的int缓冲channel ch := make(chan int, 5) 收发chan
ch &amp;lt;- elem // 发送 elem := &amp;lt;-ch //接收 // 如果ok为false,那么可能是channel已经关闭,读到的时关闭后的零值。 i, ok &amp;lt;- ch panic 情况 # 向关闭chan发送 关闭nil chan 关闭已关闭 chan 操作 nil chan 已关闭chan 正常chan 关闭 panic panic 正常关闭 读 阻塞 读可以继续读取元素,直到chan空,如果读完会读到对应类型的零值 读会阻塞,如果chan空或者没有其他goroutine写入 写 阻塞 panic 写也可能阻塞,如果chan空间不足或者没有其他goroutine读取 数据结构 # type hchan struct { qcount uint // 队列中的元素总数量 dataqsiz uint // 循环队列的长度 buf unsafe.</description>
    </item>
    
    <item>
      <title>count</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/count/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/count/</guid>
      <description> count(1) and count(*) # count(*)包括了所有的列，相当于行数，在统计结果的时候，不会忽略NULL
count(1) and count(列名) # count(1) 会统计表中的所有的记录数，不会忽略NULL，包含字段为null 的记录 count(列名) 会统计该列字段在表中出现的次数，会忽略字段为null 的情况，即不统计字段为null 的记录 执行效率 # 若列名为主键，count(列名)会比count(1)快 若列名不为主键，count(1)会比count(列名)快 若表多个列并且没有主键，则 count（1） 的执行效率优于 count（*） 若表有主键，则 select count（主键）的执行效率是最优的 若表只有一个字段，则 select count（*）最优。 优先使用count(*)或count(主键id);若主键不能用,则用count(1);若都不行才使用count(字段)
如何优化 count(*)？ # 近似值,explain 命令来表进行估算 额外表保存计数值 </description>
    </item>
    
    <item>
      <title>ddl</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/ddl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/ddl/</guid>
      <description>DDL # MySQL DDL(Data Definition Language)的是MySQL数据库的数据定义语言,用于定义和管理数据库对象,如数据库、表、列等。
主要的MySQL DDL语句包括:
CREATE:用于创建数据库对象,如创建数据库、表等。比如CREATE DATABASE、CREATE TABLE。
ALTER:用于修改数据库对象的结构或属性,如ALTER TABLE修改表结构。
DROP:用于删除数据库对象,如DROP DATABASE删除数据库,DROP TABLE删除表。
TRUNCATE:清空表中的所有行而不删除表本身。
RENAME:用来重命名数据库对象,如RENAME TABLE重命名表。
COMMENT:为数据库对象添加注释,如COMMENT ON TABLE为表添加注释。
INDEX:创建和删除数据库索引,如CREATE INDEX添加索引,DROP INDEX删除索引。
其他类似 # DML(Data Manipulation Language) # 数据操作语言,用于对数据记录进行增删改操作,比如INSERT、UPDATE、DELETE等语句。
DQL(Data Query Language) # 数据查询语言,用于对数据库进行选择和查询,主要是SELECT语句。
DCL(Data Control Language) # 数据控制语言,用于控制数据库访问权限,如GRANT和REVOKE语句。
TCL(Transaction Control Language) # 事务控制语言,用于管理数据库事务,如COMMIT、ROLLBACK、SAVEPOINT语句。
DAL(Data Analysis Language) # 数据分析语言,用于对数据库进行统计和分析计算,如COUNT、SUM、AVG函数等。
DSL(Data Definition Language) # 数据定义语言,用于定义数据库索引与视图等,如CREATE INDEX和CREATE VIEW语句。</description>
    </item>
    
    <item>
      <title>defer</title>
      <link>https://matteo-gz.github.io/coding/docs/go/defer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/defer/</guid>
      <description>流程 # 返回值 = xxx
调用defer函数
空的return</description>
    </item>
    
    <item>
      <title>delete与truncate</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/delete/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/delete/</guid>
      <description>速度:drop &amp;gt; truncate &amp;gt; DELETE
DML:delete DDL:drop,truncate
DELETE:删除表中的某些行,但不删除表结构。删除后数据行数减少,但表还存在。 TRUNCATE:清空表内所有数据,但不删除表结构。与DELETE不同的是,TRUNCATE没有事务日志,效率更高。 DROP:完全删除表,表结构和表数据一起删除。删除后无法恢复。 可以这么理解，一本书，delete是把目录撕了，truncate是把书的内容撕下来烧了，drop是把书烧了</description>
    </item>
    
    <item>
      <title>etcd</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/etcd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/etcd/</guid>
      <description>极客时间.etcd 实战课 笔记
历史 # 背景: CoreOS 团队需要一个协调服务来存储服务配置信息、提供分布式锁等能力
服务所需目标:
高可用 数据一致,提供读取&amp;quot;最新&amp;quot;数据 低容量、仅存储关键元数据配置 增删改查，监听数据变化的机制 可维护性 名字来源: unix /etc + d of distribute
历史版本变化
v0.1 # Raft算法共识 REST API 数据模型使用的是基于目录的层次模式// 参考ZooKeeper key-value 存储引擎上,简单内存树 Go语言 v0.2 # 支持consistent read CAS提供原子性 //替换掉Test And Set 机制 v2.0 # 支持quorum read v3 # 引入 B-tree,boltdb 实现一个 MVCC 数据库 数据模型从层次型目录结构改成扁平的 key-value gRPC+protobuf 特性
提供稳定可靠的事件通知 实现了事务 支持多 key 原子更新 同时基于 boltdb 的持久化存储，显著降低了 etcd 的内存占用、避免了 etcd v2 定期生成快照时的昂贵的资源开销.</description>
    </item>
    
    <item>
      <title>gc</title>
      <link>https://matteo-gz.github.io/coding/docs/go/gc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/gc/</guid>
      <description> 标记-清除算法 # STW(stop the world) 让程序暂停，程序出现卡顿
标记(Mark phase) 清除(Sweep phase) 缺点:
STW，stop the world；让程序暂停，程序出现卡顿 (重要问题)； 标记需要扫描整个heap； 清除数据会产生heap碎片。 三色并发标记法 # 说明 # 三种颜色:白色( White)、灰色(Grey)、黑色(Black)
白色:对象尚未被访问过 灰色:对象正在被访问 黑色:对象访问已完成 工作流程
开始时所有对象都为白色 根集对象(比如静态变量等)被标记为灰色 递归地遍历从根集对象开始的可达对象,将其标记为灰色 从灰色队列中取出一个对象,访问其字段和引用,将被访问的对象标记为灰色 对灰色队列中的对象进行同样操作,直到队列为空 将遍历完的灰色对象标记为黑色 从第二步开始重复遍历过程,直到没有灰色对象为止 遍历结束后,扫描内存,回收尚为白色的未使用对象 白-&amp;gt;灰-&amp;gt;黑
第一步 , 每次新创建的对象，默认的颜色都是标记为&amp;quot;白色&amp;quot; 第二步, 每次GC回收开始, 会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色” 第三步, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合 为了在GC过程中保证数据的安全，我们在开始三色标记之前就会加上STW，在扫描确定黑白对象之后再放开STW
没有STW加持下存在的问题 # 条件1: 一个白色对象被黑色对象引用(白色被挂在黑色下) 条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏(灰色同时丢了该白色) 如果当以上两个条件同时满足时，就会出现对象丢失现象!
屏障机制 # 三色不变式
强三色不变式 不存在黑色对象引用到白色对象的指针 弱三色不变式 所有被黑色对象引用的白色对象都处于灰色保护状态。 插入屏障 # 在A对象引用B对象的时候，B对象被标记为灰色
删除屏障 # 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色
缺点
插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活； 删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。 混合写屏障 # GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)， GC期间，任何在栈上创建的新对象，均为黑色。 被删除的对象标记为灰色。 被添加的对象标记为灰色。 </description>
    </item>
    
    <item>
      <title>Go框架</title>
      <link>https://matteo-gz.github.io/coding/docs/ms/framework/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/ms/framework/</guid>
      <description>简介 # https://www.techempower.com/benchmarks/
web框架 # gin doc github echo doc github hertz doc github star-history
数据库框架 # ent doc github gorm doc github star-history
微服务框架 # 来源 go-kratos doc github bilibili kitex doc github 字节跳动 go-zero doc github 晓黑板 TarsGo github 腾讯 star-history</description>
    </item>
    
    <item>
      <title>interface</title>
      <link>https://matteo-gz.github.io/coding/docs/go/interface/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/interface/</guid>
      <description>数据结构 # // 结构体表示包含方法的接口 type iface struct { tab *itab data unsafe.Pointer } // 结构体表示不包含任何方法的 interface{} 类型 type eface struct { _type *_type data unsafe.Pointer } Golang中的Interface可以被看作是一个Wrapper，它是一个包含了value和type的二元组
// 必须类型和值都为nil才算真正的nil var a interface{} = nil // tab = nil, data = nil var b interface{} = (*int)(nil) // tab 包含 *int 类型信息, data = nil fmt.Println(a == nil) // true fmt.Println(b == nil) // false 判断动态值为nil # func IsNil(i interface{}) bool { vi := reflect.</description>
    </item>
    
    <item>
      <title>k8s</title>
      <link>https://matteo-gz.github.io/coding/docs/ms/kubernetes/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/ms/kubernetes/</guid>
      <description>极客时间.深入剖析 Kubernetes
容器基础 # 容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个&amp;quot;边界&amp;quot;.
Cgroups 技术// 制造约束 Namespace 技术//修改进程视图 Namespace # 用来对各种不同的进程上下文进行“障眼法”操作
PID Mount UTS IPC Network User Cgroup // Linux 内核从 4.6 开始 PID namespace # 对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第 100 号进程
int pid = clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL); 多次执行上面的 clone(),就会创建多个 PID Namespace,每个 Namespace 里的应用进程，都会认为自己是当前容器里的第 1 号进程，它们既看不到宿主机里真正的进程空间，也看不到其他 PID Namespace 里的具体情况
障眼法 # Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时， Docker 为它们加上了各种各样的 Namespace 参数。
这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程， 只能看到各自 Mount Namespace 里挂载的目录和文件， 只能访问到各自 Network Namespace 里的网络设备， 就仿佛运行在一个个“容器”里面，与世隔绝。</description>
    </item>
    
    <item>
      <title>k8s网络</title>
      <link>https://matteo-gz.github.io/coding/docs/ms/k8s_network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/ms/k8s_network/</guid>
      <description>网络栈 # 网卡（Network Interface） 回环设备（Loopback Device） 路由表（Routing Table） iptables 规则 被隔离在它自己的 Network Namespace 当中的
在大多数情况下，我们都希望容器进程能使用自己 Network Namespace 里的网络栈，即：拥有属于自己的 IP 地址和端口</description>
    </item>
    
    <item>
      <title>kratos框架</title>
      <link>https://matteo-gz.github.io/coding/docs/ms/kratos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/ms/kratos/</guid>
      <description> 服务发现 # 熔断 # 用于提供客户端熔断功能
限流 # 用于服务端流量控制
其他 # 重试 降级 排队 </description>
    </item>
    
    <item>
      <title>map</title>
      <link>https://matteo-gz.github.io/coding/docs/go/map/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/map/</guid>
      <description>结构 # // Go map 的头部。 type hmap struct { // 注意：hmap 的格式也被编码在 cmd/compile/internal/reflectdata/reflect.go 中。 // 确保这个定义与编译器的定义保持同步。 count int // 存储在 map 中的键值对数量。必须是第一个字段（用于内置函数 len()） flags uint8 // 表示 map 的状态标志，包括了迭代器是否在使用中、是否正在进行扩容等信息。 B uint8 // 存储桶的数量的对数，实际桶的数量为len(buckets) == 2^B(bucketShift bucket的位移值)。 noverflow uint16 // 溢出桶数量的估计值。 number of overflows hash0 uint32 // 哈希种子。 buckets unsafe.Pointer // 存储键值对的桶数组，其长度为 2^B。如果 count 为 0，则可能为 nil。 oldbuckets unsafe.Pointer // 扩容时旧的桶数组，长度为 2^(B-1)，用于数据搬迁。如果没有扩容，则为 nil。 nevacuate uintptr // 扩容时已经完成搬迁的桶数量。 &amp;#34;not evacuate&amp;#34; extra *mapextra // 可选字段，指向了一些额外的 map 属性，例如 map 的类型信息和哈希函数。 } // mapextra 包含了一些不是所有 map 都有的字段。 type mapextra struct { // 如果 key 和 elem 都不包含指针，并且它们都可以内联，那么我们标记 bucket 的类型不包含指针。 // 这样可以避免扫描这样的 map。 // 然而，bmap.</description>
    </item>
    
    <item>
      <title>mongoDB</title>
      <link>https://matteo-gz.github.io/coding/docs/nosql/mongodb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/nosql/mongodb/</guid>
      <description>https://www.mongodb.com/docs/
客户端推荐 compass or navicat
服务端由cpp编写.
mongo 客户端,类似redis-cli mongod 服务端启动,类似mysqld 配置
日志目录 数据存储目录 守护进程方式启动 绑定ip启动 端口号 27017 命令
#显示数据库 show dbs #切换数据库 use &amp;lt;数据库&amp;gt; #打印当前数据库 db #删库操作 db.dropDatabase() # 创建集合 db.createCollection(name) # 显示集合 show collections # 删除集合 db.&amp;lt;集合&amp;gt;.drop() 数据库
#后台权限库 admin curd # # 集合变量的插入 https://www.mongodb.com/docs/manual/tutorial/insert-documents/ db.collection.insert() # 集合变量的多个插入 db.collection.insertMany() 查找
# 集合查找 db.collection.find() # 集合带条件查找 db.collection.find({}) # 集合查找1条 db.collection.findOne() # 让user字段显示,让name字段不显示出来 db.collection.find({},{user:1,name:0}) # 捕获错误 try{}catch(e){ print(e) } 更新
# 覆盖更新 db.</description>
    </item>
    
    <item>
      <title>OpenResty</title>
      <link>https://matteo-gz.github.io/coding/docs/web/openresty/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/web/openresty/</guid>
      <description>简介 # OpenResty 是一个兼具开发效率和性能的服务端开发平台，基于 NGINX 实现，包含反向代理和负载均衡.
核心 # NGINX 的一个 C 模块（lua-nginx-module）.
该模块将 LuaJIT 嵌入到 NGINX 服务器中，并对外提供一套完整的 Lua API，透明地支持非阻塞 I/O，提供了轻量级线程、定时器等高级抽象。
同时，围绕这个模块，OpenResty 构建了一套完备的测试框架、调试技术以及由 Lua 实现的周边功能库
用Lua 语言来进行 字符串和数值运算 查询数据库 发送 HTTP 请求 执行定时任务 调用外部命令 &amp;hellip; 可以用 FFI 的方式调用外部 C 函数 特性 # OpenResty作者章亦春, 就职于淘宝,后就职于Cloudflare
详尽的文档和测试用例 同步非阻塞 动态 例子 # cli # $ resty -e &amp;#34;ngx.say(&amp;#39;hello world&amp;#39;)&amp;#34; hello world web # events { worker_connections 1024; } http { server { listen 8080; location / { content_by_lua &amp;#39; ngx.</description>
    </item>
    
    <item>
      <title>rabbitmq</title>
      <link>https://matteo-gz.github.io/coding/docs/mq/rabbitmq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mq/rabbitmq/</guid>
      <description> 延迟队列实现 # TTL+死信队列，组合实现延迟队列的效果
TTL 消息过期时间设置 # TTL，全称Time To Live，消息过期时间设置。消息的TTL就是消息的存活时间。RabbitMQ可以对队列和消息分别设置TTL。对队列设置就是队列没有消费者连着的保留时间，也可以对每一个单独的消息做单独的设置。超过了这个时间，我们认为这个消息就死了，称之为死信。 队列过期后，会将队列所有消息全部移除。 一个队列中某一个消息过期后，只有消息在队列顶端，才会判断其是否过期(移除掉)，如果不在队列顶端，那么是无效的，过期时间有队列的过期时间判定。 如果队列设置了，消息也设置了，那么会取时间短的。所以一个消息如果被路由到不同的队列中，这个消息死亡的时间有可能不一样（不同的队列设置）。 我门一般通过设置消息的x-message-ttl属性来设置时间
死信队列 # 死信队列，英文缩写：DLX 。Dead Letter Exchange（死信交换机），当消息成为Dead message后，可以被重新发送到另一个交换机，这个交换机就是DLX。
消息成为死信的三种情况：
队列消息长度到达限制 消费者拒接消费消息，basicNack/basicReject,并且不把消息重新放入原目标队 列,requeue=false 原队列存在消息过期设置，消息到达超时时间未被消费 队列绑定死信交换机，给队列设置参数： x-dead-letter-exchange 和 x-dead-letter-routing-key，就能成功绑定了
Dead Letter Exchange其实就是一种普通的exchange，和创建其他exchange没有两样。只是在某一个设置Dead Letter Exchange的队列中有消息过期了，会自动触发消息的转发，发送到Dead Letter Exchange中去。
实现 # 延迟任务通过消息的TTL和Dead Letter Exchange来实现。 我们需要建立2个队列，一个用于发送消息，一个用于消息过期后的转发目标队列。
场景
订单超时取消 应用 # 应用解耦 流量削锋 异步消息 </description>
    </item>
    
    <item>
      <title>raft与etcd</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/raft-etcd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/raft-etcd/</guid>
      <description>主要解决问题点 # Leader选举，Leader故障后集群能快速选出新Leader； 日志复制， 集群只有Leader能写入日志， Leader负责复制日志到Follower节点，并强制Follower节点与自己保持相同； 安全性，一个任期内集群只能产生一个Leader、已提交的日志条目在发生Leader选举时，一定会存在更高任期的新Leader日志中、各个节点的状态机应用的任意位置的日志条目内容应一样等。 角色 # 角色 说明 Leader 主节点 同一时刻只有一个 Leader，负责协调和管理其他节点. 唯一性，拥有同步日志的特权，需定时广播心跳给Follower节点，以维持领导者身份。 Candidate 候选者 每一个节点都可以成为 Candidate，节点在该角色下才可以被选为新的 Leader Follower Leader 的跟随者 不可以发起选举 当Follower节点接收Leader节点心跳消息超时后，它会转变成Candidate节点，并可发起竞选Leader投票，若获得集群多数节点的支持后，它就可转变成Leader节点
graph RL F[Follower] C[Candidate] L[Leader] L--&gt;|发现更大term|F C--&gt;|发现有了新的任期或新主|F F --&gt;|长时间没有收到leader消息,开始竞选|C C--&gt;|收到一半以上选票|L 流程 # 初始化时，所有节点均为 Follower 状态。 开始选主时，所有节点的状态由 Follower 转化为 Candidate，并向其他节点发送选举请求。 其他节点根据接收到的选举请求的先后顺序，回复是否同意成为主。这里需要注意的是，在每一轮选举中，一个节点只能投出一张票。 若发起选举请求的节点获得超过一半的投票，则成为主节点，其状态转化为 Leader，其他节点的状态则由 Candidate 降为 Follower。Leader 节点与 Follower 节点之间会定期发送心跳包，以检测主节点是否活着。 当 Leader 节点的任期到了，即发现其他服务器开始下一轮选主周期时，Leader 节点的状态由 Leader 降级为 Follower，进入新一轮选主。 etcd Leader选举原理 # 下面以Leader crash场景为案例，介绍一下etcd Leader选举原理
假设集群总共3个节点，A节点为Leader，B、C节点为Follower。
Leader维持身份 # 如上Leader选举图左边部分所示， 正常情况下，Leader节点会按照心跳间隔时间，定时广播心跳消息（MsgHeartbeat消息）给Follower节点，以维持Leader身份。 Follower收到后回复心跳应答包消息（MsgHeartbeatResp消息）给Leader。</description>
    </item>
    
    <item>
      <title>SaaS多租户存储设计</title>
      <link>https://matteo-gz.github.io/coding/docs/distributed/saas/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/distributed/saas/</guid>
      <description> 数据隔离模式 # 独立数据库 实例成本高 共享数据库但隔离Schema 租户之间共享工作负载,需要迁移出大租户. 统计计费困难 数据表字段区分 需要代码兼容,研发成本高,数据安全性低. 框架流程
租户id解析,在handle业务请求时,解析出当前租户id 将租户id放入context中 根据租户id调用多租户存储连接器获取当前租户数据实例 代码层实现scope,在method行为前后进行注入. </description>
    </item>
    
    <item>
      <title>select</title>
      <link>https://matteo-gz.github.io/coding/docs/go/select/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/select/</guid>
      <description> select作用 # case后面必须是io操作 监听case，没满足阻塞 有满足，任选1个执行 default 处理case都不满足情况 select不产生忙轮询 select 自身不带有循环机制 需要借助for break跳出一个选项 </description>
    </item>
    
    <item>
      <title>slice</title>
      <link>https://matteo-gz.github.io/coding/docs/go/slice/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/slice/</guid>
      <description> 数据结构 # type slice struct { array unsafe.Pointer // 指向底层数组的指针 len int // 切片的长度 cap int // 切片的容量 } 创建 # // 此时s的长度和容量都是5。 s := make([]int, 5) // 此时s的长度是3,容量是5。 s := make([]int, 3, 5) 取值 # // 该方式没有指定开始和结束索引,是从索引0开始取到结束,即取出slice a的全部元素。 a[:] // 指定开始索引startIndex,结束索引取到结尾。比如a[1:]会从索引1开始取到最后一个元素。 a[startIndex:] // 指定结束索引endIndex,开始索引从0开始。比如a[:3]会取索引0-2的三个元素。 a[:endIndex] // 指定开始索引和结束索引区间。比如a[1:3]会取索引1和2的两个元素。 a[startIndex:endIndex] // 三个索引除了开始和结束索引外,还可以指定容量capacity。这种方式可以对slice进行扩容或缩容操作。 a[startIndex:endIndex:capacity] a[:] - 取所有元素 a[1:] - 从索引1开始取到最后 a[:3] - 取索引0-2的三个元素 a[1:3] - 取索引1和2的两个元素 a[1:3:5] - 取索引1-2但是扩容为5 </description>
    </item>
    
    <item>
      <title>一致性风险</title>
      <link>https://matteo-gz.github.io/coding/docs/redis/consistency/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/redis/consistency/</guid>
      <description>分布式锁的三个主要核心要素 # 安全性、互斥性。在同一时间内，不允许多个client同时获得锁。 活性。无论client出现crash还是遭遇网络分区，你都需要确保任意故障场景下，都不会出现死锁，常用的解决方案是超时和自动过期机制。 高可用、高性能。加锁、释放锁的过程性能开销要尽量低，同时要保证高可用，避免单点故障。 茅台超卖案例 # Redis——由分布式锁造成的重大事故
仔细分析下来，可以发现，这个抢购接口在高并发场景下，是有严重的安全隐患的，主要集中在三个地方：
没有其他系统风险容错处理 由于用户服务吃紧，网关响应延迟，但没有任何应对方式，这是超卖的导火索。
看似安全的分布式锁其实一点都不安全 虽然采用了set key value [EX seconds] [PX milliseconds] [NX|XX]的方式，但是如果线程A执行的时间较长没有来得及释放，锁就过期了，此时线程B是可以获取到锁的。当线程A执行完成之后，释放锁，实际上就把线程B的锁释放掉了。这个时候，线程C又是可以获取到锁的，而此时如果线程B执行完释放锁实际上就是释放的线程C设置的锁。这是超卖的直接原因。
非原子性的库存校验 非原子性的库存校验导致在并发场景下，库存校验的结果不准确。这是超卖的根本原因。
通过以上分析，问题的根本原因在于库存校验严重依赖了分布式锁。
因为在分布式锁正常set、del的情况下，库存校验是没有问题的。
但是，当分布式锁不安全可靠的时候，库存校验就没有用了。
其他风险 # 单Redis Master节点存在单点故障
一主多备Redis实例又因为Redis主备异步复制，当Master节点发生crash时，可能会导致同时多个client持有分布式锁，违反了锁的安全性问题
一般使用 setnx 方法，通过 Redis 实现锁和超时时间来控制锁的失效时间。但是在极端的情况下，当 Reids 主节点挂掉，但锁还没有同步到从节点时，根据哨兵机制，从就变成了主，继续提供服务。 这时，另外的线程可以再来请求锁，此时就会出现两个线程拿到了锁的情况。
setnx和expire命令分开写,没有原子性
lua脚本 SET key value NX EX seconds 忘记设置过期时间
存在app崩溃,导致锁永远无法释放 RedLock分布式锁 # 它基于多个独立的Redis Master节点工作，只要一半以上节点存活就能正常工作，同时不依赖Redis主备异步复制，具有良好的安全性、高可用性。 然而它的实现依赖于系统时间，当发生时钟跳变的时候，也会出现安全性问题</description>
    </item>
    
    <item>
      <title>业务锁的选择</title>
      <link>https://matteo-gz.github.io/coding/docs/redis/lock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/redis/lock/</guid>
      <description> etcd锁 vs redis锁 # 都可以用来保证多个服务或进程对共享资源的访问是互斥的.
特性 etcd 锁 redis 锁 实现方式 基于 etcd 的 KV 数据库 基于 redis 的 set 数据结构 一致性 强一致性 弱一致性 性能 较低 较高 可靠性 较高 较低 分布式存储系统对比点
数据存储 数据分布 数据复制 数据一致性 算法选型 盘点必要因素
工作原理 优劣势 适用场景 技术实现 </description>
    </item>
    
    <item>
      <title>事务</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/transaction/</guid>
      <description>事务特性 # 原子性 atomicity 一致性 consistency 隔离性 isolation 持久性 durability 如何保证事务特性?
持久性是通过 redo log （重做日志）来保证的； 原子性是通过 undo log（回滚日志） 来保证的； 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的； 一致性则是通过持久性+原子性+隔离性来保证； 并发问题 # 脏读 # 如果一个事务「读到」了另一个「未提交事务修改过的数据」，就意味着发生了「脏读」现象
不可重复读 # 在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了「不可重复读」现象。
幻读 # 在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象。
事务隔离级别 # read uncommitted 读未提及 # 可能发生脏读、不可重复读和幻读现象
read committed 读已提交 # 可能发生不可重复读和幻读现象
repeatable read 可重复读 # 可能发生幻读现象
MySQL InnoDB 引擎的默认隔离级别
serializable 串行化 # MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象
针对快照读（普通 select 语句），是通过 MVCC 方式解决了幻读，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。 针对当前读（select &amp;hellip; for update 等语句），是通过 next-key lock（记录锁+间隙锁）方式解决了幻读，因为当执行 select &amp;hellip; for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。 MVCC # multi-version concurrency control,多版本并发控制</description>
    </item>
    
    <item>
      <title>其他mq</title>
      <link>https://matteo-gz.github.io/coding/docs/mq/type/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mq/type/</guid>
      <description> MQ Kafka RocketMQ RabbitMQ Redis实现 基于 Redis List 的 LPUSH 和 RPOP 的实现方式 基于 Redis 的订阅或发布模式 基于 Redis 的有序集合（Sorted Set）的实现方式 </description>
    </item>
    
    <item>
      <title>数据类型</title>
      <link>https://matteo-gz.github.io/coding/docs/go/data_type/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/data_type/</guid>
      <description> 值类型 # int bool 引用类型 # chan slice map 指针 make 和 new # make 初始化内置的数据结构
slice := make([]int, 0, 100) hash := make(map[int]bool, 10) ch := make(chan int, 5) new 返回类型指针
i := new(int) var v int i := &amp;amp;v 支持平台 # // 可列出支持的平台 GOOS GOARCH go tool dist list </description>
    </item>
    
    <item>
      <title>数据类型</title>
      <link>https://matteo-gz.github.io/coding/docs/redis/data_type/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/redis/data_type/</guid>
      <description>数据类型 # string hash list set sorted Set hyperLogLog Geo bitmap Stream 数据持久化 # RDB # Redis Database 会产生多个文件，每个文件代表某一个时刻的redis数据。对于aof来说，基于rdb恢复数据会更快。
AOF # Append Only File 将每条写入命令写入日志中，在redis重启的时候通过日志文件重构数据
redis故障Rdb会丢失更多的数据，Rdb快照都是隔5分钟或者更长时间生成，而aof每隔一秒就会执行一次，所以只会丢失一秒钟的数据。
布隆过滤器 # 优点：优点很明显，二进制组成的数组，占用内存极少，并且插入和查询速度都足够快。
缺点：随着数据的增加，误判率会增加；还有无法判断数据一定存在；另外还有一个重要缺点，无法删除数据
场景 # 缓存击穿 # cache breakdown
指一些很热的数据在缓存过期后,同时有大量请求集中打击数据库,一出现就“击穿”缓存去访问数据库
热数据永不过期 加上互斥锁 缓存穿透 # cache penetration
指查询一个本来不应该存在的数据,结果却没有穿透缓存查询后台,导致对数据库的空请求
逻辑检查,小于1 或者是字符串不允许之类的 使用布隆过滤器 缓存空对象,如果是网络恶意攻击（每次key不一样，且数据库不存在），缓存占用了更多的内存,缓存空对象要考虑到缓存时间的设置 缓存雪崩 # cache avalanche
过期时间设置随机值 分布式部署且均匀分布热点数据 热数据永不过期 服务降级 服务熔断 请求限流 redis高可用 # 主从复制 用于数据备份和读写分离 哨兵机制 自动故障转移提供高可用 集群机制 节点间数据同步和分区机制实现横向扩展和强一致性 redis过期策略 # 定时删除:在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作 定期删除:每隔一段时间删除 惰性删除:获取的时候判断是否过期 Redis 选择「惰性删除+定期删除」这两种策略配和使用</description>
    </item>
    
    <item>
      <title>日志</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/log/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/log/</guid>
      <description> undo log（回滚日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。 redo log（重做日志）：是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复； binlog （归档日志）：是 Server 层生成的日志，主要用于数据备份和主从复制； relay log ,一般情况下它在MySQL主从同步读写分离集群的从节点才开启。主节点一般不需要这个日志。 </description>
    </item>
    
    <item>
      <title>服务发现</title>
      <link>https://matteo-gz.github.io/coding/docs/ms/discovery/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/ms/discovery/</guid>
      <description> 服务发现 # star-history
consul etcd 配置中心 # 方案
apollo nacos </description>
    </item>
    
    <item>
      <title>索引</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/mysql_index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/mysql_index/</guid>
      <description>指定索引 # 使用FORCE INDEX关键字强制使用指定的索引,强制使用指定的索引
SELECT * FROM table FORCE INDEX (index_name) WHERE condition; 使用USE INDEX关键字建议使用指定索引,优先使用指定的索引
SELECT * FROM table USE INDEX (index_name) WHERE condition; STRAIGHT_JOIN
强制按书写顺序连接JOIN表,固定连接顺序
索引分类 # 按数据结构分类索引 # B+tree索引 Hash索引 Full-text索引 按物理存储分类索引 # 聚簇索引（主键索引） 二级索引（辅助索引） 按字段特性分类索引 # 主键索引 唯一索引 普通索引 前缀索引 按字段个数分类索引 # 单列索引 联合索引 优化 # 覆盖索引 # 这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据
CREATE INDEX user_name_age ON user(name, age); SELECT name, age FROM user WHERE name = &amp;#39;Tom&amp;#39;; 索引下推 # 索引下推优化（index condition pushdown)， 可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数</description>
    </item>
    
    <item>
      <title>调度</title>
      <link>https://matteo-gz.github.io/coding/docs/go/gmp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/go/gmp/</guid>
      <description>优点 # 内存占用 创建和销毀 切换 GMP # GMP含义
GoRoutine Go协程，是参与调度与执行的最小单位 Machine 系统级线程 Processor 逻辑处理器 关联了的本地可运行G的队列(也称为LRQ)，最多可存放256个G 线程与进程
线程 独立调度的基本单位 进程 资源拥有的基本单位 变量 # M0 启动程序后的编号为0的主线程 G0 是每次启动一个M都会第一个创建的GoRoutine，G0仅用于负责调度的G 优势 # work stealing # 工作窃取模型。当一个P(逻辑处理器)的任务队列为空时,它可以随机从其他非空P的任务队列偷取任务来执行。这可以最大限度地提高 CPU 的利用率。
handle off # 使能M暂时释放对P的控制,让其他等待中的M接管P,从而实现充分利用多核资源。比如一个阻塞的goroutine释放了CPU,M就可以handle off,让其他M的goroutine运行。</description>
    </item>
    
    <item>
      <title>锁</title>
      <link>https://matteo-gz.github.io/coding/docs/mysql/lock/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/mysql/lock/</guid>
      <description>死锁 # 操作系统（四）—死锁
四个必要条件 # 互斥：在一个时间只能有一个进程使用资源。 请求和保持（持有并等待）：进程保持至少一个资源正在等待获取其他进程持有的额外资源。 不可抢占：一个资源只能在进程已经完成了它的任务之后，被自愿释放。 循环等待：存在n个进程，进行循环等待所占资源。 解决 # 死锁预防 死锁避免 死锁检测 死锁恢复 Mysql的锁
MySQL 有哪些锁？
根据锁粒度划分
全局锁 # Flush tables with read lock (FTWRL)
全局锁主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样
表级锁 # 表锁 # 表锁的语法
lock tables … read/write 表锁的例子
#表级别的共享锁，也就是读锁； lock tables t_student read; #表级别的独占锁，也就是写锁； lock tables t_stuent write; 主动释放
unlock tables 元数据锁 # meta data lock,MDL
MDL 锁是系统默认会加的
对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁； 例子: 给一个小表加个字段，导致整个库挂了
事务不提交，就会一直占着 MDL 锁,先暂停 DDL，或者 kill 掉这个长事务 针对热点表,在 alter table 语句里面设定等待时间,如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃 # NOWAIT: # 表示如果当前操作得不到表级别的元数据锁,会直接报错,不会等待锁释放。 # 通常情况下ALTER默认采用NOWAIT模式 ALTER TABLE tbl_name NOWAIT add column .</description>
    </item>
    
    <item>
      <title>领域驱动设计</title>
      <link>https://matteo-gz.github.io/coding/docs/ms/ddd/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://matteo-gz.github.io/coding/docs/ms/ddd/</guid>
      <description>极客时间.DDD 实战课
领域边界 # 在事件风暴中梳理业务过程中的用户操作、事件以及外部依赖关系等，根据这些要素梳理出领域实体等领域对象 根据领域实体之间的业务关联性，将业务紧密相关的实体进行组合形成聚合，同时确定聚合中的聚合根、值对象和实体。在这个图里，聚合之间的边界是第一层边界，它们在同一个微服务实例中运行，这个边界是逻辑边界，所以用虚线表示 根据业务及语义边界等因素，将一个或者多个聚合划定在一个限界上下文内，形成领域模型。在这个图里，限界上下文之间的边界是第二层边界，这一层边界可能就是未来微服务的边界，不同限界上下文内的领域逻辑被隔离在不同的微服务实例中运行，物理上相互隔离，所以是物理边界，边界之间用实线来表示 领域
这个边界内要解决的业务问题域.
在研究和解决业务问题时，DDD 会按照一定的规则将业务领域进行细分，当领域细分到一定的程度后，DDD 会将问题范围限定在特定的边界内，在这个边界内建立领域模型，进而用代码实现该领域模型，解决相应的业务问题
子域
我们把划分出来的多个子领域称为子域，每个子域对应一个更小的问题域或更小的业务范围
核心域
决定产品和公司核心竞争力的子域是核心域，它是业务成功的主要因素和公司的核心竞争力
通用域
没有太多个性化的诉求，同时被多个子域使用的通用功能子域是通用域
支撑域
子域是必需的，但既不包含决定产品和公司核心竞争力的功能，也不包含通用功能的子域，它就是支撑域.
限界上下文 Bounded Context
通用语言定义上下文含义，限界上下文则定义领域边界
通用语言
在事件风暴过程中，通过团队交流达成共识的，能够简单、清晰、准确描述业务涵义和规则的语言就是通用语言
设计过程中我们可以用一些表格，来记录事件风暴和微服务设计过程中产生的领域对象及其属性
DDD 分析和设计过程中的每一个环节都需要保证限界上下文内术语的统一，在代码模型设计的时侯就要建立领域对象和代码对象的一一映射，从而保证业务模型和代码模型的一致，实现业务语言与代码语言的统一.
领域边界就是通过限界上下文来定义的.
我们将限界上下文内的领域模型映射到微服务，就完成了从问题域到软件的解决方案.
实体 Entity # 在 DDD 中有这样一类对象，它们拥有唯一标识符，且标识符在历经各种状态变更后仍能保持一致。对这些对象而言，重要的不是其属性，而是其延续性和标识，对象的延续性和标识会跨越甚至超出软件的生命周期。我们把这样的对象称为实体
实体和值对象是组成领域模型的基础单元.
实体的代码形态
充血模型 实体的运行形态
实体以 DO（领域对象）的形式存在，每个实体对象都有唯一的 ID. 值对象 ValueObject # 通过对象属性值来识别的对象，它将多个相关属性组合为一个概念整体.值对象本质上就是一个集.
在领域建模时，我们可以将部分对象设计为值对象，保留对象的业务涵义，同时又减少了实体的数量；在数据建模时，我们可以将值对象嵌入实体，减少实体表的数量，简化数据库设计.
DDD 提倡从领域模型设计出发，而不是先设计数据模型.
聚合 Aggregate # 领域模型内的实体和值对象就好比个体，而能让实体和值对象协同工作的组织就是聚合，它用来确保这些领域对象在实现共同的业务逻辑时，能保证数据的一致性。
聚合根 AggregateRoot
如果把聚合比作组织，那聚合根就是这个组织的负责人。聚合根也称为根实体，它不仅是实体，还是聚合的管理者。
聚合的构建过程 采用事件风暴，根据业务行为，梳理出在投保过程中发生这些行为的所有的实体和值对象，比如投保单、标的、客户、被保人等等。 从众多实体中选出适合作为对象管理者的根实体，也就是聚合根。判断一个实体是否是聚合根，你可以结合以下场景分析：是否有独立的生命周期？是否有全局唯一 ID？是否可以创建或修改其它对象？是否有专门的模块来管这个实体。图中的聚合根分别是投保单和客户实体。 根据业务单一职责和高内聚原则，找出与聚合根关联的所有紧密依赖的实体和值对象。构建出 1 个包含聚合根（唯一）、多个实体和值对象的对象集合，这个集合就是聚合。在图中我们构建了客户和投保这两个聚合。 在聚合内根据聚合根、实体和值对象的依赖关系，画出对象的引用和依赖模型。这里我需要说明一下：投保人和被保人的数据，是通过关联客户 ID 从客户聚合中获取的，在投保聚合里它们是投保单的值对象，这些值对象的数据是客户的冗余数据，即使未来客户聚合的数据发生了变更，也不会影响投保单的值对象数据。从图中我们还可以看出实体之间的引用关系，比如在投保聚合里投保单聚合根引用了报价单实体，报价单实体则引用了报价规则子实体。 多个聚合根据业务语义和上下文一起划分到同一个限界上下文内。 聚合设计原则</description>
    </item>
    
  </channel>
</rss>
